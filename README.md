# Bangla News Article Abstractive Summarization

This repository contains code and resources for performing abstractive summarization of Bangla news articles using state-of-the-art pretrained Transformer models, specifically BanglaT5 and mT5. The project utilizes the Hugging Face Transformers library and the XLSum dataset for training and evaluation.

## Overview

Abstractive summarization aims to generate concise and meaningful summaries that capture the key points of a given text while preserving its core information. In this project, I focus on summarizing Bangla news articles, leveraging the power of pretrained Transformer models to produce high-quality abstractive summaries.

## Features

- Utilizes BanglaT5 and mT5 pretrained Transformer models for abstractive summarization in the Bangla language.
- Incorporates the Hugging Face Transformers library for model implementation and fine-tuning.
- Training and evaluation performed using the XLSum dataset, consisting of 1.35 million professionally annotated article-summary pairs sourced from BBC Bangla news articles.
- Allows for easy replication and experimentation with different model architectures and hyperparameters for improved summarization performance.

## Requirements

- Python 3.x
- Hugging Face Transformers library
- XLSum dataset

## Dataset Link
- https://huggingface.co/datasets/csebuetnlp/xlsum/viewer/bengali
  
